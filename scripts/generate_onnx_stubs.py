import argparse
import inspect
import itertools
import os
import sys

parser = argparse.ArgumentParser()
parser.add_argument(
  "onnx_cpp2py_export",
  help="path to directory of onnx_cpp2py_export.so"
)
parser.add_argument(
  "include",
  help="path to directory where to save headers"
)
parser.add_argument(
  "stubs",
  help="path to directory where to save stubs"
)
args = parser.parse_args()

path_onnx_cpp2py_export = os.path.realpath(os.path.abspath(args.onnx_cpp2py_export))
path_include = os.path.realpath(os.path.abspath(args.include))
path_stubs = os.path.realpath(os.path.abspath(args.stubs))

print(f"path onnx_cpp2py_export: {path_onnx_cpp2py_export}")
print(f"path include: {path_include}")
print(f"path stubs: {path_stubs}")

sys.path.insert(0, path_onnx_cpp2py_export)
import onnx_cpp2py_export

schemas = onnx_cpp2py_export.defs.get_all_schemas()

template_header = '''
//this file was generated by {script}
#ifndef OPERATOR_{NAME}_H
#define OPERATOR_{NAME}_H

#include "operator.h"
#include "onnx.pb-c.h"

/**
 * Onnx operator '{Name}' version {version}
 *
 * @param[in]  n_input     Number of inputs ({input_constraint})
 * @param[in]  input       Array of pointers to the inputs
 * @param[in]  n_attribute Number of attributes
 * @param[in]  attribute   Array of pointers to the attributes
 * @param[in]  n_output    Numper of outputs ({output_constraint})
 * @param[out] output      Array of pointer to the outputs
 * @return                 Error code
 *
 * @retval     0        No Error
 * @retval     ENOSYS   Operator is stubbed
 * @retval     EINVAL   Invalid argument
 * @retval     ENOMEM   Out of Memory
 * @retval     EFAULT   Invalid addr
 * @retval     EDOM     Math argument out of domain
 * @retval     ERANGE   Math result not representable
 *
{doc}
{deprecated}
{types}
{inputs}
{outputs}
{attributes}
 * @since version {version}
 * @see {file}:{line}
{documentation}
 */
{deprecated_attribute} int operator_{name}_{version}(
  size_t                  n_input,
  Onnx__TensorProto    ** input,
  size_t                  n_attribute,
  Onnx__AttributeProto ** attribute,
  size_t                  n_output,
  Onnx__TensorProto    ** output
);
{stubs}
#endif
'''

template_stub = '''
__attribute__((weak, alias("operator_stub")))
extern int operator_{name}_{version}{type}(
  size_t                  n_input,
  Onnx__TensorProto    ** input,
  size_t                  n_attribute,
  Onnx__AttributeProto ** attribute,
  size_t                  n_output,
  Onnx__TensorProto    ** output
);
'''

template_operators = '''
//this file was generated by {script}

#ifndef OPERATORS_H
#define OPERATORS_H

{includes}

#endif
'''

def size_constraint(min, max):
  if (min == max):
    return "always {0}".format(min)
  else:
    return "{0} to {1}".format(min, max)

def format_text(prefix, start, texts):
  output = []

  curr = [start]
  for text in texts:
    lines = []
    length = len(prefix) + len(start)
    # split text into words by splitting on space and remove empty splits ("  ")
    # then split on newline boundaries, but keep emtpy splits ("\n\n") 
    words = [ w.split("\n") for w in text.strip().split(" ") if w!=""]
    words = list(itertools.chain(*words))
    for w in words:
      if w == "":
        # empty split, caused by "\n\n", should cause line break
        length = len(prefix) + len(start) + len(w)
        lines.append(prefix + " ".join(curr))
        curr = [" "*len(start)]
        continue
      if length + len(w) < 79:
        # keep adding words
        length += len(w) + 1
        curr.append(w)
        continue
      
      # line is full, do line break
      length = len(prefix) + len(start) + len(w)
      lines.append(prefix + " ".join(curr))
      curr = [" "*len(start)]
      curr.append(w)
    lines.append(prefix + " ".join(curr))
    curr = [" "*len(start)]
    output.append("\n".join(lines))
  
  return "\n".join(output)

def sanitize_type(t):
  replacements = {
    " ":"",
    "_":"",
    ",":"_",
    "(":"",
    ")":"",
    "tensor":"t",
    "map":"m",
    "seq":"s"
  }
  for r in replacements.items():
    t = t.lower().replace(*r)
  return t.upper()

def permute_types(types):
  p = ['']
  for t in types:
    names = [ f"{t.type_param_str}_{sanitize_type(n)}" for n in t.allowed_type_strs ]
    p = [ "__".join(x) for x in itertools.product(p,names) ]
  p.sort()
  return p

for schema in schemas:
  deprecated = " * " + "@deprecated Avoid usage!" * schema.deprecated
  deprecated_attribute = "__attribute__((deprecated))\n" * schema.deprecated
  documentation = " * "
  types = []
  inputs = []
  outputs = []
  attributes = []

  if schema.domain == '':
    documentation += "@see https://github.com/onnx/onnx/blob/master/docs/Operators.md#" + schema.name
  elif schema.domain == 'ai.onnx.ml':
    documentation += "@see https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md#" + schema.name
  
  doc = format_text(" *","",[schema.doc])

  for c in schema.type_constraints:
    allowed = list(c.allowed_type_strs)
    allowed.sort()
    types.append(f" * Type {c.type_param_str}:")
    types.append(format_text(" * ", "  ", [c.description, ", ".join(allowed)]))
    types.append(' * ')

  if types:
    types = "\n".join(types)
  else:
    types = " *"

  for i in schema.inputs:
    allowed = list(i.types)
    allowed.sort()
    inputs.append(f" * Input {i.typeStr} {i.name}:")
    inputs.append(format_text(" * ", "  ", [i.description, ", ".join(allowed)]))
    inputs.append(' * ')
 
  if inputs:
    inputs = "\n".join(inputs)
  else:
    inputs = " *"

  for o in schema.outputs:
    allowed = list(o.types)
    allowed.sort()
    outputs.append(f" * Output {o.typeStr} {o.name}:")
    outputs.append(format_text(" * ", "  ", [o.description, ", ".join(allowed)]))
    outputs.append(' * ')

  if outputs:
    outputs = "\n".join(outputs)
  else:
    outputs = " *"

  for a in schema.attributes.values():
    required = "(optional)"
    if a.required:
      required = "(required)"
    attributes.append(f" * Attribute {a.type.name} {a.name} {required}:")
    attributes.append(format_text(" *", "  ", [a.description]))
    attributes.append(' * ')

  if attributes:
    attributes = "\n".join(attributes)
  else:
    attributes = " *"

  stubs = [ template_stub.format(
    name = schema.name.lower(),
    version = schema.since_version,
    type = t
  ) for t in permute_types(schema.type_constraints)]
  stubs = "".join( stubs )

  header = template_header.format(
    _ws_=" "*len(schema.name),
    attributes=attributes,
    deprecated_attribute=deprecated_attribute,
    deprecated=deprecated,
    doc=doc,
    documentation=documentation,
    file=os.path.relpath(schema.file, path_include),
    input_constraint=size_constraint(schema.min_input, schema.max_input),
    inputs=inputs,
    line=schema.line,
    Name=schema.name.capitalize(),
    name=schema.name.lower(),
    NAME=schema.name.upper(),
    output_constraint=size_constraint(schema.min_output, schema.max_output),
    outputs=outputs,
    script=inspect.getfile(inspect.currentframe()),
    stubs=stubs,
    version=schema.since_version,
    types=types,
  )

  os.makedirs(f"{path_include}/{schema.domain}",exist_ok=True)
  open(f"{path_include}/{schema.domain}/operator_{schema.name.lower()}.h","w").write(header)

includes = [ f'#include "operator_{s.name.lower()}.h"' for s in schemas ]
operators = template_operators.format(
  includes="\n".join(includes),
  script=inspect.getfile(inspect.currentframe()),
)

open(f"{path_include}/operators.h","w").write(operators)
