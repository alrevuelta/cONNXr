//this file was generated by ../../../../../../scripts/onnx_generator/OperatorTemplate.py
#include "operator__ai_onnx__reshape__5.h"
#include "tracing.h"
#include "utils.h"

operator_status
prepare_operator__ai_onnx__reshape__5(
    node_context *ctx
)
{
    TRACE_ENTRY(1);

    TRACE_NODE(2, true, ctx->onnx_node);

    /* UNCOMMENT AS NEEDED */

    Onnx__TensorProto *i_data = searchInputByName(ctx, 0);
    Onnx__TensorProto *i_shape = searchInputByName(ctx, 1);

    TRACE_TENSOR(2, true, i_data);
    TRACE_TENSOR(2, true, i_shape);

    Onnx__TensorProto *o_reshaped = searchOutputByName(ctx, 0);

    /* ALLOCATE AND INITIALIZE CONTEXT HERE IF NEEDED */

    // context_operator__ai_onnx__reshape__5 *op_ctx = NULL;
    // op_ctx = malloc(sizeof(context_operator__ai_onnx__reshape__5));
    // TRACE_FATAL(0 , !op_ctx, "could not allocate executer_context");

    /* INITIALIZE OUTPUTS DATA_TYPE AND SHAPE HERE */

    // Not sure about this implementation. It just swaps the dimensions
    // and does not change the data.

    o_reshaped->has_raw_data = 0;
    o_reshaped->data_type    = i_data->data_type;
    o_reshaped->n_dims       = i_shape->n_int64_data;
    o_reshaped->dims         = malloc(o_reshaped->n_dims * sizeof(int64_t));

    // Note that the dimension that is applied is encoded as a
    // int64 field. So shape its assumed to have data_type int64
    for (int i = 0; i < i_shape->n_int64_data; i++)
    {
        // The dimension can be n, 0 or -1.
        if (i_shape->int64_data[i] == 0)
        {
            // If 0 the dimension is not changed
            o_reshaped->dims[i] = i_data->dims[i];
        }
        else if (i_shape->int64_data[i] == -1)
        {
        // If -1 the dimension is inferred from the remaining dim
        // Only 1 parameter can be -1

        // This is ugly af, just to make it work for now
        uint64_t totalDimData = 1;
        for (int j = 0; j < i_data->n_dims; j++)
        {
            totalDimData *= i_data->dims[j];
        }

        uint64_t totalShape = 1;

        for (int j = 0; j < i_shape->n_int64_data; j++)
        {
            if (i_shape->int64_data[j] > 0)
            {
                totalShape *= i_shape->int64_data[j];
            }
            else if (i_shape->int64_data[j] == 0)
            {
                totalShape *= i_data->dims[j];
            }
            // Just ignore if -1
        }
            o_reshaped->dims[i] = totalDimData/totalShape;
        } else {
            o_reshaped->dims[i] = i_shape->int64_data[i];
        }
    }

    /* MALLOC OUTPUT TENSORS HERE */

    mallocTensorData(o_reshaped);

    TRACE_TENSOR(2, true, o_reshaped);

    /* CHOOSE EXECUTER AND CONTEXT HERE */
    /* YOU MAY USE THE GENERATED RESOLVER */

    ctx->executer = resolve_operator__ai_onnx__reshape__5(ctx);
    // ctx->executer_context = op_ctx;

    TRACE_EXIT(1);

    /* CHANGE RETURN CODE IF THIS PREPARER IS VALID */
    // return OP_ENOSYS;
    return OP_OK;
}