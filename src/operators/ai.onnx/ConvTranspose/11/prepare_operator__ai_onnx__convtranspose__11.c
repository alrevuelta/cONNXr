//this file was generated by ../../../../../../scripts/onnx_generator/OperatorTemplate.py
#include "operator__ai_onnx__convtranspose__11.h"
#include "tracing.h"
#include "utils.h"

int calcOutputSize(int inputSize, int kernelSize, int stride, int dilations, int padStart, int padEnd) {
    return stride * (inputSize - 1) + ((kernelSize - 1) * dilations + 1 - padStart - padEnd);
}

operator_status
prepare_operator__ai_onnx__convtranspose__11(
    node_context *ctx
)
{
    TRACE_ENTRY(1);

    TRACE_NODE(2, true, ctx->onnx_node);

    /* UNCOMMENT AS NEEDED */

    Onnx__TensorProto *i_X = searchInputByName(ctx, 0);
    Onnx__TensorProto *i_W = searchInputByName(ctx, 1);
    Onnx__TensorProto *i_B = searchInputByName(ctx, 2);

    // TRACE_TENSOR(2, true, i_X);
    // TRACE_TENSOR(2, true, i_W);
    // TRACE_TENSOR(2, B, i_B);

    // Onnx__AttributeProto *a_auto_pad = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"auto_pad");
    Onnx__AttributeProto *a_dilations = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"dilations");
    Onnx__AttributeProto *a_group = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"group");
    //https://github.com/onnx/onnx/issues/785
    //'kernel_shape' parameter is redundant and can be inferred from the input
    // Onnx__AttributeProto *a_kernel_shape = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"kernel_shape");
    // Onnx__AttributeProto *a_output_padding = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"output_padding");
    // Onnx__AttributeProto *a_output_shape = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"output_shape");
    Onnx__AttributeProto *a_pads = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"pads");
    Onnx__AttributeProto *a_strides = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"strides");

    // TRACE_ATTRIBUTE(2, a_auto_pad, a_auto_pad);
    // TRACE_ATTRIBUTE(2, a_dilations, a_dilations);
    // TRACE_ATTRIBUTE(2, a_group, a_group);
    // TRACE_ATTRIBUTE(2, a_kernel_shape, a_kernel_shape);
    // TRACE_ATTRIBUTE(2, a_output_padding, a_output_padding);
    // TRACE_ATTRIBUTE(2, a_output_shape, a_output_shape);
    // TRACE_ATTRIBUTE(2, a_pads, a_pads);
    // TRACE_ATTRIBUTE(2, a_strides, a_strides);

    Onnx__TensorProto *o_Y = searchOutputByName(ctx, 0);

    /* ALLOCATE AND INITIALIZE CONTEXT HERE IF NEEDED */

    // char* default_auto_pad = ;
    // size_t default_n_dilations = ;
    // int64_t* default_dilations = ;

    int64_t default_group;
    if(a_group == NULL) {
        default_group = 1;
    } else {

        //we cant handle groups != 1
        if(a_group->i != 1) {
            return OP_EDOM;
        }

        default_group = a_group->i;
    }

    if(i_X->n_dims != 4) {
        printf("%zu\n", i_X->n_dims);
        printf("please use convtranspose only with a 2D input (4D tensor)\n");
        return OP_EDOM;
    }

    if(i_X->dims[0]!= 1) {
        printf("please use convtranspose only with batchsize of 1\n");
        return OP_EDOM;
    }

    int inputSizeX = i_X->dims[3];
    int inputSizeY = i_X->dims[2];
    int inputChannels = i_X->dims[1];

    if(inputChannels != i_W->dims[0]) {
        printf("size of input channels needs to be qual with weights\n");
        return OP_EINVAL;
    }
    
    int kernelSizeX = i_W->dims[3];
    int kernelSizeY = i_W->dims[2];
    int outputChannels = i_W->dims[1];

        if(i_B != NULL) {
        int biasSize = i_B->dims[0];
        if(biasSize != i_W->dims[1] * default_group) {
            printf("size of input channels needs to be qual with weights\n");
            return OP_EINVAL;
        }
    }

    int strideX = 1;
    int strideY = 1;

    if(a_strides != NULL) {
        strideX = a_strides->ints[1];
        strideY = a_strides->ints[0];
    }

    int dilationsX = 1;
    int dilationsY = 1;

    if(a_dilations != NULL) {
        dilationsX = a_dilations->ints[1];
        dilationsY = a_dilations->ints[0];
    }

    int padStartY = 0;
    int padStartX = 0;
    int padEndY = 0;
    int padEndX = 0;

    if(a_pads != NULL) {
        if(a_pads->n_ints != 4) {
            return OP_EDOM;
        }

        padStartY = a_pads->ints[0];
        padStartX = a_pads->ints[1];
        padEndY = a_pads->ints[2];
        padEndX = a_pads->ints[3];
    }

    int outputSizePaddedX = calcOutputSize(inputSizeX, kernelSizeX, strideX, dilationsX, padStartX, padEndX);
    int outputSizePaddedY = calcOutputSize(inputSizeY, kernelSizeY, strideY, dilationsY, padStartY, padEndY);
    
    // size_t default_n_kernel_shape = ;
    // int64_t* default_kernel_shape = ;
    // size_t default_n_output_padding = ;
    // int64_t* default_output_padding = ;
    // size_t default_n_output_shape = ;
    // int64_t* default_output_shape = ;
    // size_t default_n_pads = ;
    // int64_t* default_pads = ;
    // size_t default_n_strides = ;
    // int64_t* default_strides = ;

    context_operator__ai_onnx__convtranspose__11 *op_ctx = NULL;
    op_ctx = malloc(sizeof(context_operator__ai_onnx__convtranspose__11));
    TRACE_FATAL(0 , !op_ctx, "could not allocate executer_context");

    // op_ctx->auto_pad = a_auto_pad?strndup((char*)a_auto_pad->s.data, a_auto_pad->s.len):default_auto_pad;
    // op_ctx->n_dilations = a_dilations?a_dilations->n_ints:default_n_dilations;
    // op_ctx->dilations = a_dilations?a_dilations->ints:ARRAYDUP(default_dilations,default_n_dilations);
    // TRACE_FATAL(0, !op_ctx->dilations, "malloc failed");
    // op_ctx->group = a_group?a_group->i:default_group;
    // op_ctx->n_kernel_shape = a_kernel_shape?a_kernel_shape->n_ints:default_n_kernel_shape;
    // op_ctx->kernel_shape = a_kernel_shape?a_kernel_shape->ints:ARRAYDUP(default_kernel_shape,default_n_kernel_shape);
    // TRACE_FATAL(0, !op_ctx->kernel_shape, "malloc failed");
    // op_ctx->n_output_padding = a_output_padding?a_output_padding->n_ints:default_n_output_padding;
    // op_ctx->output_padding = a_output_padding?a_output_padding->ints:ARRAYDUP(default_output_padding,default_n_output_padding);
    // TRACE_FATAL(0, !op_ctx->output_padding, "malloc failed");
    // op_ctx->n_output_shape = a_output_shape?a_output_shape->n_ints:default_n_output_shape;
    // op_ctx->output_shape = a_output_shape?a_output_shape->ints:ARRAYDUP(default_output_shape,default_n_output_shape);
    // TRACE_FATAL(0, !op_ctx->output_shape, "malloc failed");
    // op_ctx->n_pads = a_pads?a_pads->n_ints:default_n_pads;
    // op_ctx->pads = a_pads?a_pads->ints:ARRAYDUP(default_pads,default_n_pads);
    // TRACE_FATAL(0, !op_ctx->pads, "malloc failed");
    // op_ctx->n_strides = a_strides?a_strides->n_ints:default_n_strides;
    // op_ctx->strides = a_strides?a_strides->ints:ARRAYDUP(default_strides,default_n_strides);
    // TRACE_FATAL(0, !op_ctx->strides, "malloc failed");

    // TRACE_VAR(2, true, op_ctx->auto_pad, "\"%s\"");
    // TRACE_ARRAY(2, true, op_ctx->dilations, , op_ctx->n_dilations, "%" PRId64);
    // TRACE_VAR(2, true, op_ctx->group, "%" PRId64);
    // TRACE_ARRAY(2, true, op_ctx->kernel_shape, , op_ctx->n_kernel_shape, "%" PRId64);
    // TRACE_ARRAY(2, true, op_ctx->output_padding, , op_ctx->n_output_padding, "%" PRId64);
    // TRACE_ARRAY(2, true, op_ctx->output_shape, , op_ctx->n_output_shape, "%" PRId64);
    // TRACE_ARRAY(2, true, op_ctx->pads, , op_ctx->n_pads, "%" PRId64);
    // TRACE_ARRAY(2, true, op_ctx->strides, , op_ctx->n_strides, "%" PRId64);

    /* INITIALIZE OUTPUTS DATA_TYPE AND SHAPE HERE */


    o_Y->n_dims       = i_X->n_dims;
    o_Y->dims         = malloc(o_Y->n_dims * sizeof(int64_t));
    o_Y->has_raw_data = 0;
    o_Y->data_type    = ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT;
    o_Y->n_float_data = outputSizePaddedX*outputSizePaddedY*outputChannels;

    o_Y->dims[0] = 1;
    o_Y->dims[1] = outputChannels;
    o_Y->dims[2] = outputSizePaddedY;
    o_Y->dims[3] = outputSizePaddedX;

    /* MALLOC OUTPUT TENSORS HERE */

    //mallocTensorData(o_Y);
    o_Y->float_data = (float*)malloc(outputSizePaddedX * outputSizePaddedY * outputChannels * sizeof(float));

    // TRACE_TENSOR(2, true, o_Y);

    /* CHOOSE EXECUTER AND CONTEXT HERE */
    /* YOU MAY USE THE GENERATED RESOLVER */

    ctx->executer = resolve_operator__ai_onnx__convtranspose__11(ctx);
    ctx->executer_context = op_ctx;

    TRACE_EXIT(1);

    /* CHANGE RETURN CODE IF THIS PREPARER IS VALID */
    //return OP_ENOSYS;
    return OP_OK;
}