//this file was generated by ../../../../../../scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__CONVTRANSPOSE__11_H
# define OPERATOR_OPERATOR__AI_ONNX__CONVTRANSPOSE__11_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'ConvTranspose' version 11
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * The convolution transpose operator consumes an input tensor and a filter,
 * and computes the output.
 * 
 * If the pads parameter is provided the shape of the output is calculated via the following equation:
 * 
 *   output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]
 * 
 * output_shape can also be explicitly specified in which case pads values are auto generated using these equations:
 * 
 *   total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]
 *   If (auto_pads != SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)
 *   Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).
 * 
 * Constraint T:
 *   Constrain input and output types to float tensors.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Input T X:
 *   Input data tensor from previous layer; has size (N x C x H x W), where N
 *   is the batch size, C is the number of channels, and H and W are the height
 *   and width. Note that this is for the 2D image. Otherwise the size is (N x
 *   C x D1 x D2 ... x Dn)
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * 
 * Input T W:
 *   The weight tensor that will be used in the convolutions; has size (C x
 *   M/group x kH x kW), where C is the number of channels, and kH and kW are
 *   the height and width of the kernel, and M is the number of feature maps.
 *   For more than 2 dimensions, the weight shape will be (C x M/group x k1 x
 *   k2 x ... x kn), where (k1 x k2 x ... x kn) is the dimension of the kernel.
 *   The number of channels in the output should be equal to W.shape[1] * group
 *   (assuming zero based indices of the shape array)
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * 
 * Input T B:
 *   Optional 1D bias to be added to the convolution, has size of M.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Output T Y:
 *   Output data tensor that contains the result of the convolution. The
 *   output dimensions are functions of the kernel size, stride size, pad
 *   lengths and group count. The number of channels in the output should be
 *   equal to W.shape[1] * group (assuming zero based indices of the shape
 *   array)
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Attribute STRING auto_pad (optional):
 *   auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where
 *   default value is NOTSET, which means explicit padding is used. SAME_UPPER
 *   or SAME_LOWER mean pad the input so that the output spatial size match the
 *   input.In case of odd number add the extra padding at the end for
 *   SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.
 * 
 * Attribute INTS dilations (optional):
 *   dilation value along each spatial axis of the filter. If not present, the
 *   dilation defaults to 1 along each spatial axis.
 * 
 * Attribute INT group (optional):
 *   number of groups input channels and output channels are divided into.
 * 
 * Attribute INTS kernel_shape (optional):
 *   The shape of the convolution kernel. If not present, should be inferred
 *   from input W.
 * 
 * Attribute INTS output_padding (optional):
 *   Additional elements added to the side with higher coordinate indices in
 *   the output. Each padding value in "output_padding" must be less than the
 *   corresponding stride/dilation dimension. By default, this attribute is a
 *   zero vector. Note that this attribute doesn't directly affect the computed
 *   output values. It only controls the selection of the computed values, so
 *   changing this attribute only adds or removes output elements. If
 *   "output_shape" is explicitly provided, "output_padding" does not
 *   contribute additional size to "output_shape" but participates in the
 *   computation of the needed padding amount. This is also called adjs or
 *   adjustment in some frameworks.
 * 
 * Attribute INTS output_shape (optional):
 *   The shape of the output can be explicitly set which will cause pads
 *   values to be auto generated. If output_shape is specified pads values are
 *   ignored. See doc for details for equations to generate pads
 * 
 * Attribute INTS pads (optional):
 *   Padding for the beginning and ending along each spatial axis, it can take
 *   any value greater than or equal to 0. The value represent the number of
 *   pixels added to the beginning and end part of the corresponding axis.
 *   `pads` format should be as follow [x1_begin, x2_begin...x1_end,
 *   x2_end,...], where xi_begin the number of pixels added at the beginning of
 *   axis `i` and xi_end, the number of pixels added at the end of axis `i`.
 *   This attribute cannot be used simultaneously with auto_pad attribute. If
 *   not present, the padding defaults to 0 along start and end of each spatial
 *   axis.
 * 
 * Attribute INTS strides (optional):
 *   Stride along each spatial axis. If not present, the stride defaults to 1
 *   along each spatial axis.
 *
 * @since version 11
 *
 * @see tmp/pip-req-build-t1yqduuy/onnx/defs/nn/defs.cc:1446
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose
 */

operator_status
prepare_operator__ai_onnx__convtranspose__11(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__convtranspose__11;

typedef struct {
    char* auto_pad;
    size_t n_dilations;
    int64_t* dilations;
    int64_t group;
    size_t n_kernel_shape;
    int64_t* kernel_shape;
    size_t n_output_padding;
    int64_t* output_padding;
    size_t n_output_shape;
    int64_t* output_shape;
    size_t n_pads;
    int64_t* pads;
    size_t n_strides;
    int64_t* strides;

} context_operator__ai_onnx__convtranspose__11;

operator_executer
resolve_operator__ai_onnx__convtranspose__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__convtranspose__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__convtranspose__11__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__convtranspose__11__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__convtranspose__11__T_tensor_float16(
    node_context *ctx
);

# endif